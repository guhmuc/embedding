{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c9a0c3f-7059-4b34-b559-e58ff56595a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.spatial import distance\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans\n",
    "from umap import UMAP\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from pathlib import Path, PurePath\n",
    "import tiktoken\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "from  concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb8af7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gheiss/workspaces/jupyter'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()\n",
    "#os.chdir(\"diesunddas\")\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einfache Progress-Anzeige\n",
    "def progress(total, stop = 100):\n",
    "    i = 1\n",
    "    while True:\n",
    "        pct = i / total * 100\n",
    "#        if i % int(total / 1000) == 0:\n",
    "        d = int(total * 0.0001 * stop)\n",
    "        #if d == 0 or i % d == 0 or pct >= stop:\n",
    "        if True:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"{i} / {math.ceil(total)} ({min(round(pct,1),100)}%)\")\n",
    "        \n",
    "        if pct >= stop: \n",
    "            yield True \n",
    "        else:\n",
    "            i += 1\n",
    "            yield \n",
    "            \n",
    "def chunker(seq, size):\n",
    "    for pos in range(0, len(seq), size):\n",
    "        yield seq.iloc[pos:pos + size] \n",
    "\n",
    "class Embedding:\n",
    "    \n",
    "    client = OpenAI()\n",
    "\n",
    "    def __init__(self, model = \"text-embedding-3-small\"):\n",
    "        \"\"\"Creates a new (empty) embedding with the given model\"\"\"\n",
    "        \n",
    "        self.model = model \n",
    "        self.encoding = tiktoken.encoding_for_model(model)\n",
    "        \n",
    "    def __count_tokens(self, text_to_embed):\n",
    "        tcnt = len(self.encoding.encode(text_to_embed))\n",
    "        return tcnt\n",
    "\n",
    "    def __get_embeddings(self, texts_to_embed):\n",
    "        response = self.client.embeddings.create(\n",
    "            model=self.model,\n",
    "            input=texts_to_embed,\n",
    "            encoding_format=\"float\"\n",
    "        )\n",
    "        return map(lambda d: d.embedding, response.data)\n",
    "\n",
    "    def __process_batch(self, batch_df, prog):\n",
    "        results = self.__get_embeddings(batch_df[self.column])\n",
    "        for i in enumerate(results):\n",
    "            self.df.at[batch_df.index[i[0]], \"__embedding\"] = i[1]\n",
    "        next(prog)\n",
    "\n",
    "\n",
    "    def __process_df(self, nsamples=0, contains=\"\", dryrun=False, chunksize=0, parallel=20):\n",
    "        self.df = self.df[self.df[self.column].str.contains(contains)]\n",
    "        if nsamples > 0 : self.df = self.df.sample(nsamples)\n",
    "        self.df[\"__embedding\"] = \"\"\n",
    "        self.df[\"__tcnt\"] = self.df[self.column].astype(str).apply(self.__count_tokens) \n",
    "        if not dryrun and len(self.df) > 0: \n",
    "            if chunksize == 0 : chunksize = int(8192 / self.df[\"__tcnt\"].max() * 0.7) \n",
    "            print(\"chunksize: \", chunksize)\n",
    "            prog = progress(len(self.df)/chunksize)    \n",
    "            with ThreadPoolExecutor(max_workers=parallel) as executor:\n",
    "                for batch_df in chunker(self.df, chunksize):\n",
    "                    executor.submit(self.__process_batch, batch_df, prog)            \n",
    "\n",
    "        print(f\"Number of tokens: {self.df['__tcnt'].sum()}\")\n",
    "        print(f\"Created {len(self.df)} embeddings.\")\n",
    "\n",
    "\n",
    "    def store(self):\n",
    "        \"\"\"Stores the embedding alongside the input file the embedding was created from, with the suffix .mbd.h5\"\"\"\n",
    "        \n",
    "        with pd.HDFStore(self.cache, 'w') as store:\n",
    "            store.put('data', self.df)\n",
    "            store.get_storer('data').attrs.metadata = {\"path\": self.path, \"column\": self.column}\n",
    "            print(f\"Stored Embedding to {self.cache}\")\n",
    "        return self\n",
    "\n",
    "    def load(self, filename, contains=\"\"):\n",
    "        \"\"\"Loads an embedding that was previously stored.\"\"\"\n",
    "        \n",
    "        print(f\"Loading Embedding from {self.to_cache_path(filename)}\") \n",
    "        with pd.HDFStore(self.to_cache_path(filename), \"r\") as store:\n",
    "            self.df = store.get(\"data\")\n",
    "            metadata = store.get_storer('data').attrs.metadata\n",
    "            self.path = metadata[\"path\"]\n",
    "            self.column = metadata[\"column\"]\n",
    "            self.df = self.df.dropna(subset=[self.column])\n",
    "            self.df = self.df[self.df[self.column].str.contains(contains)]\n",
    "        print(f\"Loaded {len(self.df)} embeddings.\")\n",
    "        return self\n",
    "\n",
    "    def from_csv(self, path, delimiter=\";\", column=\"text\", nsamples=0, contains=\"\", dryrun=False, chunksize=0, parallel=20):\n",
    "        \"\"\"\n",
    "        Build an embedding from the given CSV file. \n",
    "        \n",
    "        column: The named column in the CSV file to get the text to embed from.\n",
    "        nsamples: Only use nsamples random lines to build the embedding.\n",
    "        contains: Only use lines containing the given text\n",
    "        dryrun: Do not call any APIs \n",
    "        chunksize: How many lines are included in a single API calls. If omitted or 0, the optimal chunksize is estimated automatically.\n",
    "        parallel: Number of parallel requests.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.path = Path(path).absolute()\n",
    "        self.cache = self.path.with_suffix(\".mbd.h5\")\n",
    "        self.column = column\n",
    "        self.df = pd.read_csv(self.path, sep=delimiter)        \n",
    "        print(f\"Reading from {self.path}\")\n",
    "        self.__process_df(nsamples=nsamples, dryrun=dryrun, chunksize=chunksize, parallel=parallel)\n",
    "        return self   \n",
    "\n",
    "    def from_xls(self, path, sheet=\"\", column=\"text\", nsamples=0, contains=\"\", dryrun=False, chunksize=0, parallel=20):\n",
    "        \"\"\"\n",
    "        Build an embedding from the given excel file. \n",
    "        \n",
    "        Same arguments as from_csv() plus:\n",
    "        sheet: Name of the shhet to read.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.path = Path(path).absolute()\n",
    "        self.cache = self.path.with_suffix(\".mbd.h5\")\n",
    "        self.column = column        \n",
    "        with pd.ExcelFile(path) as xls:  \n",
    "            self.df = pd.read_excel(xls, sheet)  \n",
    "        print(f\"Reading from {self.path}\")\n",
    "        self.__process_df(nsamples=nsamples, contains=contains, dryrun=dryrun, chunksize=chunksize, parallel=parallel)\n",
    "        return self   \n",
    "\n",
    "    def from_array(self, texts, nsamples=0, contains=\"\", dryrun=False, chunksize=0, parallel=20):\n",
    "        \"\"\"\n",
    "        Build an embedding from an array. \n",
    "\n",
    "        Same arguments as from_csv().        \n",
    "        \"\"\"\n",
    "\n",
    "        self.column = \"__text\"\n",
    "        self.df = pd.DataFrame()\n",
    "        self.df[self.column] = texts\n",
    "        self.__process_df(nsamples=nsamples, contains=contains, dryrun=dryrun, chunksize=chunksize, parallel=parallel)\n",
    "        return self   \n",
    "        \n",
    "    @staticmethod\n",
    "    def to_cache_path(orig_path):\n",
    "        cach_path = Path(orig_path).absolute().with_suffix(\".mbd.h5\")\n",
    "        return cach_path\n",
    "        \n",
    "    @classmethod\n",
    "    def match_embeddings(cls, input, target):\n",
    "        if len(input.df) == 0 or len(target.df) == 0:\n",
    "            return\n",
    "\n",
    "        similarities = cosine_similarity (\n",
    "            input.df.loc[:,\"__embedding\"].tolist(), \n",
    "            target.df.loc[:,\"__embedding\"].tolist())\n",
    "        maxes = similarities.argmax(axis=1)\n",
    "\n",
    "        hits = list(map(lambda i: target.df.loc[i,target.column].strip(), maxes))\n",
    "\n",
    "        res = pd.DataFrame()\n",
    "        res[\"in\"] = input.df.loc[:,input.column]\n",
    "        res[\"out\"] = hits\n",
    "        res.to_csv(\"testresult.csv\", sep=\";\", index=False)\n",
    "        return res        \n",
    "\n",
    "    @classmethod\n",
    "    def similarity_matrix(cls, input, target):\n",
    "        if len(input.df) == 0 or len(target.df) == 0:\n",
    "            return\n",
    "        similarities = cosine_similarity (\n",
    "            input.df.loc[:,\"__embedding\"].tolist(), \n",
    "            target.df.loc[:,\"__embedding\"].tolist())\n",
    "        df = pd.DataFrame(similarities, columns=list(target.df[target.column]), index=list(input.df[input.column]))\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f80e4ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "zds_latest_06 = Embedding().from_csv(\"../precitooldata/zds_latest/zds_categories_with_path_06.csv\", column='categoryPathShort').store()\n",
    "broken_cats = Embedding().from_xls(\"../precitooldata/EDEfalscheKategorien.xlsx\", sheet=\"finalV2\", column=\"ede\").store()\n",
    "\n",
    "#broken_cats = Embedding().load(\"../precitooldata/EDEfalscheKategorien.xlsx\")\n",
    "#Embedding.match_embeddings(broken_cats, zds_latest_06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b6b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_cats = Embedding().load(\"../precitooldata/zds_latest/zds_categories_with_path_06.csv\")\n",
    "#target_cats = Embedding().load(\"../precitooldata/zds_latest/zds_categories_with_path.csv\", contains=\"69_Betriebseinrichtung\")\n",
    "#Embedding.match_embeddings(broken_cats, target_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d59f733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1 (100%)\n",
      "Nuber of tokens: 6\n",
      "Created 2 embeddings.\n",
      "       nagetier  wohnzimmer\n",
      "maus   0.448305    0.266702\n",
      "haus   0.263480    0.401299\n",
      "laus   0.143407    0.176122\n",
      "ratte  0.635840    0.324984\n"
     ]
    }
   ],
   "source": [
    "bla = Embedding(model=\"text-embedding-3-large\").from_array([\"maus\", \"haus\", \"laus\", \"ratte\"])\n",
    "blub = Embedding(model=\"text-embedding-3-large\").from_array([\"nagetier\", \"wohnzimmer\"])\n",
    "print(Embedding.similarity_matrix(bla, blub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ad20c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embedding from /Users/gheiss/workspaces/jupyter/embedding/targetcolors.mbd.h5\n",
      "Loaded 18 embeddings.\n",
      "Loading Embedding from /Users/gheiss/workspaces/jupyter/embedding/testcolors.mbd.h5\n",
      "Loaded 79 embeddings.\n",
      "                in        out\n",
      "0             blau       blue\n",
      "1             grau       grey\n",
      "2             gelb     yellow\n",
      "3            beige      beige\n",
      "4             weiß      white\n",
      "..             ...        ...\n",
      "74      türkisblau  turquoise\n",
      "75  vintage indigo  turquoise\n",
      "76           weiss      white\n",
      "77           white      white\n",
      "78          yellow     yellow\n",
      "\n",
      "[79 rows x 2 columns]\n",
      "                   black      grey     beige     white      blue     brown  \\\n",
      "blau            0.342835  0.409396  0.381652  0.330763  0.561244  0.345590   \n",
      "grau            0.347526  0.630660  0.449944  0.355024  0.323822  0.393050   \n",
      "gelb            0.281950  0.378548  0.408017  0.329555  0.324214  0.323200   \n",
      "beige           0.331640  0.434184  0.857109  0.381737  0.331725  0.453607   \n",
      "weiß            0.306213  0.352912  0.376551  0.550555  0.278849  0.244569   \n",
      "...                  ...       ...       ...       ...       ...       ...   \n",
      "türkisblau      0.233058  0.301304  0.309854  0.257870  0.383229  0.244539   \n",
      "vintage indigo  0.251908  0.271954  0.329813  0.239567  0.353498  0.257411   \n",
      "weiss           0.322888  0.391930  0.423851  0.489043  0.288489  0.318785   \n",
      "white           0.399503  0.399684  0.419033  0.710485  0.333425  0.314721   \n",
      "yellow          0.370930  0.402648  0.449381  0.491880  0.412441  0.393594   \n",
      "\n",
      "                turquoise    petrol     green       red    purple      pink  \\\n",
      "blau             0.437762  0.258805  0.371755  0.354539  0.377362  0.385917   \n",
      "grau             0.300387  0.220601  0.356697  0.294482  0.332011  0.338417   \n",
      "gelb             0.298221  0.244855  0.364649  0.341348  0.316695  0.346915   \n",
      "beige            0.379388  0.239985  0.330208  0.321779  0.331302  0.412437   \n",
      "weiß             0.231851  0.184319  0.253182  0.245864  0.251304  0.287251   \n",
      "...                   ...       ...       ...       ...       ...       ...   \n",
      "türkisblau       0.573105  0.206785  0.309325  0.229071  0.290747  0.311959   \n",
      "vintage indigo   0.354180  0.223225  0.227210  0.261505  0.289907  0.300874   \n",
      "weiss            0.262271  0.188544  0.286245  0.284183  0.297875  0.308553   \n",
      "white            0.308956  0.209654  0.304492  0.305880  0.287226  0.351841   \n",
      "yellow           0.378728  0.254449  0.427754  0.427914  0.386134  0.423013   \n",
      "\n",
      "                  orange    yellow      oliv      gold    silver  multicolored  \n",
      "blau            0.369946  0.351608  0.313059  0.296202  0.270063      0.320577  \n",
      "grau            0.327643  0.306575  0.277192  0.272879  0.288495      0.292228  \n",
      "gelb            0.408750  0.604380  0.294945  0.354078  0.272386      0.276603  \n",
      "beige           0.392342  0.381353  0.265704  0.300507  0.265505      0.318074  \n",
      "weiß            0.258193  0.287690  0.222692  0.237659  0.255380      0.222946  \n",
      "...                  ...       ...       ...       ...       ...           ...  \n",
      "türkisblau      0.304598  0.255585  0.239701  0.230606  0.228312      0.290106  \n",
      "vintage indigo  0.297825  0.225938  0.259429  0.239123  0.231956      0.275368  \n",
      "weiss           0.322205  0.334375  0.287391  0.312753  0.315196      0.246046  \n",
      "white           0.333366  0.368138  0.247166  0.277285  0.290725      0.293370  \n",
      "yellow          0.502034  0.691438  0.327955  0.391619  0.319958      0.393185  \n",
      "\n",
      "[79 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "#target_colors = Embedding(model=\"text-embedding-3-large\").from_csv(\"embedding/targetcolors.csv\", nsamples=0).store()\n",
    "#test_colors = Embedding(model=\"text-embedding-3-large\").from_csv(\"embedding/testcolors.csv\", column=\"search\", nsamples=0).store()\n",
    "\n",
    "target = Embedding().load(\"embedding/targetcolors.csv\")\n",
    "test = Embedding().load(\"embedding/testcolors.csv\")\n",
    "\n",
    "print(Embedding.match_embeddings(test, target))\n",
    "print(Embedding.similarity_matrix(test, target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
